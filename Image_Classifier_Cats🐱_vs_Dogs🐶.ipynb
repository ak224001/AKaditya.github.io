{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classifier-Catsüê±_vs_Dogsüê∂.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUuwm4WAisDAXxQRylesT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak224001/AKaditya.github.io/blob/master/Image_Classifier_Cats%F0%9F%90%B1_vs_Dogs%F0%9F%90%B6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI5_EGDlOqDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEm4MtM7O2EW",
        "colab_type": "code",
        "outputId": "fd79dd5a-9505-48b9-b448-9a266a90d1c2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-271b27d3-bad5-4816-b5f0-2d388f979a9b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-271b27d3-bad5-4816-b5f0-2d388f979a9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHc8pF1_PQBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ! mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M2wqcimPWSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ZtUlM3Pdm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQwNIgqRPg0z",
        "colab_type": "code",
        "outputId": "a57f896a-32df-47b1-b3be-332d69ccd821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test1.zip to /content\n",
            " 98% 265M/271M [00:03<00:00, 137MB/s]\n",
            "100% 271M/271M [00:03<00:00, 89.6MB/s]\n",
            "Downloading train.zip to /content\n",
            " 96% 523M/543M [00:03<00:00, 148MB/s]\n",
            "100% 543M/543M [00:03<00:00, 157MB/s]\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 81.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H0CxJhVQ_V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmZ3PLpOTtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auDaZ1TRpXad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = \"/content/train/\"\n",
        "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYoYMKPJZBM",
        "colab_type": "code",
        "outputId": "fcfdee28-949e-46d2-9192-470ab8149113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cat_files = [fn for fn in train_images if 'cat' in fn]\n",
        "dog_files = [fn for fn in train_images if 'dog' in fn]\n",
        "len(cat_files), len(dog_files)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 12500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73ZujxlKJH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation set with 3000 images\n",
        "cat_validate = np.random.choice(cat_files, size = 1500 ,replace = False )\n",
        "dog_validate = np.random.choice(dog_files, size = 1500 ,replace = False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw4hp0Rt6uCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test set\n",
        "cat_files = list(set(cat_files) - set(cat_validate))\n",
        "dog_files = list(set(dog_files) - set(dog_validate))\n",
        "cat_test = np.random.choice(cat_files, size=2500, replace=False)\n",
        "dog_test = np.random.choice(dog_files, size=2500, replace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9uk2wKoLgbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_train = list(set(cat_files) - set(cat_test))\n",
        "dog_train = list(set(dog_files) - set(dog_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiLtjjqH8On7",
        "colab_type": "code",
        "outputId": "1d6420cb-629e-4f4d-cb8c-007c6e395cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Cat datasets:', len(cat_train), len(cat_validate), len(cat_test))\n",
        "print('Dog datasets:', len(dog_train), len(dog_validate), len(dog_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cat datasets: 8500 1500 2500\n",
            "Dog datasets: 8500 1500 2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj7XMOKLMH4K",
        "colab_type": "text"
      },
      "source": [
        "**training , test , validation dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57UdqJbo-B4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'training_data'\n",
        "val_dir = 'validation_data'\n",
        "test_dir = 'test_data'\n",
        "\n",
        "#merge dataset \n",
        "train_files = np.concatenate([cat_train,dog_train])\n",
        "validate_files = np.concatenate([cat_validate, dog_validate])\n",
        "test_files = np.concatenate([cat_test, dog_test])\n",
        "\n",
        "#make files\n",
        "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
        "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\n",
        "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYoZRWTTLBjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fn in validate_files:\n",
        "    shutil.copy(fn, val_dir)\n",
        "for fn in train_files:\n",
        "    shutil.copy(fn, train_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz7I6D1_-946",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fn in test_files:\n",
        "    shutil.copy(fn, test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-Xl7U_6PMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# TRAIN_DIR = \"/content/training_data/\"\n",
        "# training_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
        "# TRAIN_DIR = \"/content/validation_data/\"\n",
        "# validation_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgyxzGQ2W37N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(validation_images),len(training_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q52KtWNrPncH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in train_files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMdPQwKOMnvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
        "# validation_imgs = np.array(validation_imgs)\n",
        "# validation_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in validation_files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j_vGXFzqFyf",
        "colab_type": "text"
      },
      "source": [
        "**Train datset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "texMQVHLRVcM",
        "colab_type": "code",
        "outputId": "21b455b8-1d1b-4f66-bca4-50282189eb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "# define location of dataset\n",
        "import os\n",
        "folder = \"/content/training_data/\"\n",
        "photos, labels = list(), list()\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "\t# determine class\n",
        "\toutput = 0.0\n",
        "\tif file.startswith('cat'):\n",
        "\t\toutput = 1.0\n",
        "\t# load image\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "\t# convert to numpy array\n",
        "\tphoto = img_to_array(photo)\n",
        "\t# store\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "# convert to a numpy arrays\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "print(photos.shape, labels.shape)\n",
        "# save the reshaped photos\n",
        "save('dogs_vs_cats_photos.npy', photos)\n",
        "save('dogs_vs_cats_labels.npy', labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17000, 200, 200, 3) (17000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2t1c7h1pR2J",
        "colab_type": "text"
      },
      "source": [
        "**validation dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wjddH2NdNK",
        "colab_type": "code",
        "outputId": "41a9d8d5-1d89-4e76-c787-2c482333ce56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define location of dataset\n",
        "import os\n",
        "folder = \"/content/validation_data/\"\n",
        "photos, labels = list(), list()\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "\t# determine class\n",
        "\toutput = 0.0\n",
        "\tif file.startswith('cat'):\n",
        "\t\toutput = 1.0\n",
        "\t# load image\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "\t# convert to numpy array\n",
        "\tphoto = img_to_array(photo)\n",
        "\t# store\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "# convert to a numpy arrays\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "print(photos.shape, labels.shape)\n",
        "# save the reshaped photos\n",
        "save('dogs_vs_cats_photos_validation.npy', photos)\n",
        "save('dogs_vs_cats_labels_validation.npy', labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 200, 200, 3) (3000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSSo0Ymt7fCQ",
        "colab_type": "text"
      },
      "source": [
        "TEST DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoUSE9Ns7duR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "# define location of dataset\n",
        "import os\n",
        "folder = \"/content/test_data/\"\n",
        "photos, labels = list(), list()\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "\t# determine class\n",
        "\toutput = 0.0\n",
        "\tif file.startswith('cat'):\n",
        "\t\toutput = 1.0\n",
        "\t# load image\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "\t# convert to numpy array\n",
        "\tphoto = img_to_array(photo)\n",
        "\t# store\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "# convert to a numpy arrays\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "print(photos.shape, labels.shape)\n",
        "# save the reshaped photos\n",
        "save('dogs_vs_cats_photos_test.npy', photos)\n",
        "save('dogs_vs_cats_labels_test.npy', labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQUdpPQAWQ4Y",
        "colab_type": "text"
      },
      "source": [
        "!rm -rf training_data                                #to delete any folder and subfolder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191XNMFjQDuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "train_photos = load('dogs_vs_cats_photos.npy')\n",
        "train_labels = load('dogs_vs_cats_labels.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD6Jl3CubGbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs_scaled = train_photos.astype('float32')\n",
        "train_imgs_scaled /= 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpVzrtz_eHIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_photos = load('dogs_vs_cats_photos_validation.npy')\n",
        "validate_labels = load('dogs_vs_cats_labels_validation.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4cCHK7deXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "validation_imgs_scaled  = validate_photos.astype('float32')\n",
        "validation_imgs_scaled /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LhEVbZO_k90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and confirm the shape\n",
        "from numpy import load\n",
        "test_photos = load('dogs_vs_cats_photos_test.npy')\n",
        "test_labels = load('dogs_vs_cats_labels_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ku60fXuWuev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytpDHoem_8nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs_scaled  = test_photos.astype('float32')\n",
        "test_imgs_scaled /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaXkNJIOghC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "import keras,os\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(input_shape=(200,200,3),filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024,activation=\"relu\"))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(units=512,activation=\"relu\"))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(),\n",
        "#               metrics=['accuracy'])\n",
        "              \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frJd5ZGqtG5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile model\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZEF7tYgkNvM",
        "colab_type": "code",
        "outputId": "f0ac416c-dce7-49e6-c98d-842f7a99c052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 30\n",
        "num_classes = 2\n",
        "epochs = 30\n",
        "import tensorflow as tf\n",
        "import os\n",
        "# Train the model with the new callback\n",
        "history = model.fit(x=train_imgs_scaled, y=train_labels,batch_size=batch_size,epochs=epochs,verbose=1,\n",
        "                    validation_data=(validation_imgs_scaled, validate_labels)                 \n",
        "                    )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 17000 samples, validate on 3000 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "17000/17000 [==============================] - 67s 4ms/step - loss: 0.6928 - acc: 0.5086 - val_loss: 0.6928 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6912 - acc: 0.5351 - val_loss: 0.6911 - val_acc: 0.5073\n",
            "Epoch 3/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.6854 - acc: 0.5582 - val_loss: 0.6835 - val_acc: 0.5703\n",
            "Epoch 4/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6769 - acc: 0.5733 - val_loss: 0.6674 - val_acc: 0.5950\n",
            "Epoch 5/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6591 - acc: 0.5995 - val_loss: 0.6446 - val_acc: 0.6157\n",
            "Epoch 6/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6373 - acc: 0.6162 - val_loss: 0.6148 - val_acc: 0.6440\n",
            "Epoch 7/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6180 - acc: 0.6331 - val_loss: 0.5939 - val_acc: 0.6593\n",
            "Epoch 8/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.6117 - acc: 0.6406 - val_loss: 0.5894 - val_acc: 0.6737\n",
            "Epoch 9/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5984 - acc: 0.6568 - val_loss: 0.5886 - val_acc: 0.6730\n",
            "Epoch 10/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5869 - acc: 0.6639 - val_loss: 0.5772 - val_acc: 0.6813\n",
            "Epoch 11/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5837 - acc: 0.6725 - val_loss: 0.6215 - val_acc: 0.6357\n",
            "Epoch 12/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5741 - acc: 0.6839 - val_loss: 0.5677 - val_acc: 0.6890\n",
            "Epoch 13/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5716 - acc: 0.6889 - val_loss: 0.5609 - val_acc: 0.6867\n",
            "Epoch 14/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5629 - acc: 0.6973 - val_loss: 0.5855 - val_acc: 0.6617\n",
            "Epoch 15/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5633 - acc: 0.6978 - val_loss: 0.5363 - val_acc: 0.7257\n",
            "Epoch 16/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5511 - acc: 0.7058 - val_loss: 0.5360 - val_acc: 0.7223\n",
            "Epoch 17/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5441 - acc: 0.7125 - val_loss: 0.5369 - val_acc: 0.7283\n",
            "Epoch 18/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5315 - acc: 0.7269 - val_loss: 0.5187 - val_acc: 0.7350\n",
            "Epoch 19/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5216 - acc: 0.7362 - val_loss: 0.5131 - val_acc: 0.7437\n",
            "Epoch 20/30\n",
            "17000/17000 [==============================] - 50s 3ms/step - loss: 0.5115 - acc: 0.7419 - val_loss: 0.5162 - val_acc: 0.7400\n",
            "Epoch 21/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.5027 - acc: 0.7518 - val_loss: 0.4854 - val_acc: 0.7630\n",
            "Epoch 22/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4929 - acc: 0.7548 - val_loss: 0.4761 - val_acc: 0.7733\n",
            "Epoch 23/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4821 - acc: 0.7643 - val_loss: 0.4776 - val_acc: 0.7680\n",
            "Epoch 24/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4710 - acc: 0.7728 - val_loss: 0.4704 - val_acc: 0.7727\n",
            "Epoch 25/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4607 - acc: 0.7790 - val_loss: 0.4588 - val_acc: 0.7780\n",
            "Epoch 26/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4580 - acc: 0.7818 - val_loss: 0.4454 - val_acc: 0.7903\n",
            "Epoch 27/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4437 - acc: 0.7910 - val_loss: 0.4526 - val_acc: 0.7877\n",
            "Epoch 28/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4306 - acc: 0.7971 - val_loss: 0.4573 - val_acc: 0.7880\n",
            "Epoch 29/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4217 - acc: 0.8065 - val_loss: 0.4180 - val_acc: 0.8177\n",
            "Epoch 30/30\n",
            "17000/17000 [==============================] - 51s 3ms/step - loss: 0.4131 - acc: 0.8065 - val_loss: 0.4099 - val_acc: 0.8190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ceHsvLLef4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1-2oIHv_e3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model|\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owma4GrvHlXu",
        "colab_type": "code",
        "outputId": "6fabbbcf-6c29-4b20-d7bb-40e460d2a2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(test_imgs_scaled, test_labels, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 81.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqlcZ2x-jlp",
        "colab_type": "code",
        "outputId": "d238ad2b-b205-48da-d471-be3da2b0f4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "source": [
        "# load json and create model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acFWc_OqUqXf",
        "colab_type": "code",
        "outputId": "bbf2f1ff-be07-46ea-9673-982c10575c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# compile model\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "loaded_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVZuaxdbTish",
        "colab_type": "code",
        "outputId": "e4ed85e9-8951-42b8-8310-54e26921acb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "print('\\n# Evaluate on test data')\n",
        "results = loaded_model.evaluate(test_imgs_scaled,test_labels, batch_size=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "5000/5000 [==============================] - 5s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e0db8fd1-34ad-4d8f-8a7e-e854ffcf11f3",
        "id": "IRNwiRnOWRJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3968415895402431, 0.8183999965190888]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkdqvMt-Wcra",
        "colab_type": "text"
      },
      "source": [
        "**Less Complex Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0x7C0tsWSBT",
        "colab_type": "code",
        "outputId": "d20eef43-b789-449b-d4e2-3d5e41030d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "import keras,os\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(input_shape=(200,200,3),filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024,activation=\"relu\"))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(units=512,activation=\"relu\"))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(),\n",
        "#               metrics=['accuracy'])\n",
        "              \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 25, 25, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36864)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              37749760  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 38,672,737\n",
            "Trainable params: 38,672,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3LJBcAqWYe3",
        "colab_type": "code",
        "outputId": "795c37ae-5c37-407b-b5c9-22a31321533d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# compile model\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GENQlCvWpUo",
        "colab_type": "code",
        "outputId": "57022b4e-2d8f-4d31-cecc-92638e8f5fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 30\n",
        "num_classes = 2\n",
        "epochs = 30\n",
        "import tensorflow as tf\n",
        "import os\n",
        "# Train the model with the new callback\n",
        "history = model.fit(x=train_imgs_scaled, y=train_labels,batch_size=batch_size,epochs=epochs,verbose=1,\n",
        "                    validation_data=(validation_imgs_scaled, validate_labels)                 \n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 17000 samples, validate on 3000 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "17000/17000 [==============================] - 49s 3ms/step - loss: 0.6900 - acc: 0.5324 - val_loss: 0.6893 - val_acc: 0.5180\n",
            "Epoch 2/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6779 - acc: 0.5751 - val_loss: 0.6948 - val_acc: 0.5223\n",
            "Epoch 3/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6580 - acc: 0.6010 - val_loss: 0.6555 - val_acc: 0.6180\n",
            "Epoch 4/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6438 - acc: 0.6165 - val_loss: 0.6577 - val_acc: 0.5960\n",
            "Epoch 5/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6307 - acc: 0.6295 - val_loss: 0.6498 - val_acc: 0.6007\n",
            "Epoch 6/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6207 - acc: 0.6386 - val_loss: 0.6148 - val_acc: 0.6473\n",
            "Epoch 7/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6112 - acc: 0.6490 - val_loss: 0.6066 - val_acc: 0.6533\n",
            "Epoch 8/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.6033 - acc: 0.6548 - val_loss: 0.6044 - val_acc: 0.6483\n",
            "Epoch 9/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5946 - acc: 0.6654 - val_loss: 0.6046 - val_acc: 0.6517\n",
            "Epoch 10/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5858 - acc: 0.6734 - val_loss: 0.5710 - val_acc: 0.6853\n",
            "Epoch 11/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5685 - acc: 0.6934 - val_loss: 0.6349 - val_acc: 0.6257\n",
            "Epoch 12/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5554 - acc: 0.7085 - val_loss: 0.6091 - val_acc: 0.6550\n",
            "Epoch 13/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5456 - acc: 0.7159 - val_loss: 0.5439 - val_acc: 0.7060\n",
            "Epoch 14/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5322 - acc: 0.7302 - val_loss: 0.5707 - val_acc: 0.6890\n",
            "Epoch 15/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5211 - acc: 0.7377 - val_loss: 0.5681 - val_acc: 0.6997\n",
            "Epoch 16/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5132 - acc: 0.7424 - val_loss: 0.5334 - val_acc: 0.7230\n",
            "Epoch 17/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.5028 - acc: 0.7491 - val_loss: 0.5310 - val_acc: 0.7260\n",
            "Epoch 18/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4917 - acc: 0.7562 - val_loss: 0.5537 - val_acc: 0.7140\n",
            "Epoch 19/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4828 - acc: 0.7675 - val_loss: 0.4988 - val_acc: 0.7517\n",
            "Epoch 20/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4751 - acc: 0.7675 - val_loss: 0.5315 - val_acc: 0.7227\n",
            "Epoch 21/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4651 - acc: 0.7745 - val_loss: 0.5196 - val_acc: 0.7277\n",
            "Epoch 22/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4546 - acc: 0.7815 - val_loss: 0.4885 - val_acc: 0.7597\n",
            "Epoch 23/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4392 - acc: 0.7886 - val_loss: 0.4863 - val_acc: 0.7567\n",
            "Epoch 24/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4287 - acc: 0.7993 - val_loss: 0.4473 - val_acc: 0.7860\n",
            "Epoch 25/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4207 - acc: 0.8051 - val_loss: 0.4357 - val_acc: 0.7887\n",
            "Epoch 26/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.4039 - acc: 0.8164 - val_loss: 0.4495 - val_acc: 0.7797\n",
            "Epoch 27/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.3924 - acc: 0.8214 - val_loss: 0.4115 - val_acc: 0.8043\n",
            "Epoch 28/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.3748 - acc: 0.8339 - val_loss: 0.4013 - val_acc: 0.8170\n",
            "Epoch 29/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.3586 - acc: 0.8381 - val_loss: 0.3862 - val_acc: 0.8190\n",
            "Epoch 30/30\n",
            "17000/17000 [==============================] - 34s 2ms/step - loss: 0.3436 - acc: 0.8465 - val_loss: 0.3917 - val_acc: 0.8087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIgnJUIkWx1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37w7TZh3cE1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model|\n",
        "model.save_weights(\"model2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H47zGeecV7d",
        "colab_type": "code",
        "outputId": "ce1bfaba-7954-40a5-b44c-3250c7f14578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# load json and create model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model2.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFYoBvgcd6w4",
        "colab_type": "code",
        "outputId": "c556c6bb-f9ba-4694-d38b-44883b98632d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# compile model\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "loaded_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxNSdI-XddYs",
        "colab_type": "code",
        "outputId": "e1b49cd9-9773-44ce-8e05-3c1ab2e103ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = loaded_model.evaluate(test_imgs_scaled, test_labels, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 81.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0zTEXXJePG9",
        "colab_type": "text"
      },
      "source": [
        "**The accuracy of both models is approximate same.................**\n",
        "**First model accuracy--->82.84%**...........\n",
        "**Second model accuracy--->82.82%**"
      ]
    }
  ]
}